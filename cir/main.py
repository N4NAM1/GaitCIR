import os
# è®¾ç½® HF é•œåƒ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import argparse
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.utils.data import DataLoader
from torch.utils.data.distributed import DistributedSampler
from transformers import CLIPProcessor, get_scheduler
from torch.optim import AdamW
from tqdm import tqdm

# === å¼•å…¥é¡¹ç›®æ¨¡å— ===
import config as cfg
from modeling.demo_model import GaitCIRModel
from data.dataset_loader import GaitCIRDataset
from data.collate import get_collate_fn
from utils.Metrics import compute_hierarchical_metrics

# === ç¯å¢ƒé…ç½®ï¼šé˜²æ­¢ OpenCV å¤šçº¿ç¨‹æ­»é” ===
import cv2
cv2.setNumThreads(0)
cv2.ocl.setUseOpenCL(False)


def get_parser():
    """ å‘½ä»¤è¡Œå‚æ•°è§£æ """
    parser = argparse.ArgumentParser(description='GaitCIR Main Program')
    
    # === DDP å¿…è¦å‚æ•° ===
    parser.add_argument('--local_rank', type=int, default=0, help="DDP Local Rank")
    parser.add_argument('--local-rank', type=int, default=0, help="Torch launch compatibility")
    
    # === åŸºç¡€è¿è¡Œå‚æ•° ===
    parser.add_argument('--phase', default='train', choices=['train', 'test'], help="Run mode")
    parser.add_argument('--seed', default=42, type=int, help="Random seed")
    parser.add_argument('--gpu', default='0,1,2,3', type=str, help="Visible GPUs (info only)")
    
    # === åŠ¨æ€è¦†ç›– Config ===
    parser.add_argument('--no_feat', action='store_true', help="Force Image Mode (Raw RGB)")
    parser.add_argument('--unmasked', action='store_true', help="Force Unmasked Features")
    parser.add_argument('--ckpt', default=None, type=str, help="Checkpoint path for testing")
    
    return parser


def initialization(args):
    """
    ç¯å¢ƒåˆå§‹åŒ–ï¼šDDP è¿æ¥ã€éšæœºç§å­ã€é…ç½®æ›´æ–°
    """
    # === 1. è‡ªåŠ¨æ£€æµ‹å¹¶è¡¥å…¨ DDP ç¯å¢ƒå˜é‡ (å…¼å®¹ç›´æ¥è¿è¡Œ python main.py) ===
    if 'RANK' not in os.environ and 'WORLD_SIZE' not in os.environ:
        print("âš ï¸ [Init] No DDP environment found. Falling back to Single-GPU Mode.")
        os.environ['RANK'] = '0'
        os.environ['WORLD_SIZE'] = '1'
        os.environ['MASTER_ADDR'] = 'localhost'
        os.environ['MASTER_PORT'] = '12345' # é»˜è®¤ç«¯å£
        os.environ['LOCAL_RANK'] = '0'
    
    # === 2. DDP åˆå§‹åŒ– ===
    # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ LOCAL_RANK
    if 'LOCAL_RANK' in os.environ:
        args.local_rank = int(os.environ['LOCAL_RANK'])
    
    # æ­¤æ—¶ os.environ ä¸­ä¸€å®šæœ‰ LOCAL_RANK (è¦ä¹ˆæ˜¯ torchrun è®¾çš„ï¼Œè¦ä¹ˆæ˜¯æˆ‘ä»¬ä¸Šé¢è¡¥å…¨çš„)
    torch.cuda.set_device(args.local_rank)
    dist.init_process_group(backend='nccl', init_method='env://')
    
    # æ›´æ–°å…¨å±€è®¾å¤‡é…ç½®
    cfg.DEVICE = torch.device("cuda", args.local_rank)

    # === 3. éšæœºç§å­ ===
    seed = args.seed + dist.get_rank()
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # === 4. åŠ¨æ€æ›´æ–° Config ===
    if args.no_feat:
        cfg.USE_FEATURES = False
        if dist.get_rank() == 0: print("âš ï¸ [Config] Override: Forced Image Mode (Raw RGB)")
    
    if args.unmasked:
        cfg.FEATURE_ROOT = cfg.FEATURE_ROOT_UNMASKED
        cfg.USE_MASK = False
        if dist.get_rank() == 0: print("âš ï¸ [Config] Override: Using UNMASKED Data")
    
    # === 5. æ‰“å°ä¿¡æ¯ ===
    if dist.get_rank() == 0:
        print(f"ğŸš€ [Init] DDP Initialized. World Size: {dist.get_world_size()}")
        print(f"ğŸš€ [Init] Phase: {args.phase} | Feature Mode: {cfg.USE_FEATURES} | Mask: {cfg.USE_MASK}")
        print(f"ğŸš€ [Loss] Inv Type: {cfg.LOSS_INV_TYPE} | Alpha: {cfg.LOSS_ALPHA}")


def run_model(args):
    """ æ¨¡å‹æ„å»ºä¸å¼•æ“åˆ†å‘ """
    # 1. æ„å»ºæ¨¡å‹
    if dist.get_rank() == 0: print(f"ğŸ—ï¸ [Model] Building Backbone: {cfg.MODEL_ID}")
    
    model = GaitCIRModel(cfg.MODEL_ID).to(cfg.DEVICE)
    processor = CLIPProcessor.from_pretrained(cfg.MODEL_ID)
    
    # 2. åŠ è½½æƒé‡
    if args.phase == 'test':
        if args.ckpt is None:
            raise ValueError("âŒ [Error] --ckpt is required for testing phase!")
        if dist.get_rank() == 0: print(f"ğŸ“¥ [Model] Loading Checkpoint: {args.ckpt}")
        state_dict = torch.load(args.ckpt, map_location=cfg.DEVICE)
        model.combiner.load_state_dict(state_dict)

    # 3. DDP å°è£…
    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)
    model = nn.parallel.DistributedDataParallel(
        model, 
        device_ids=[args.local_rank], 
        output_device=args.local_rank,
        find_unused_parameters=True 
    )

    # 4. å¯åŠ¨å¼•æ“
    if args.phase == 'train':
        train_engine(model, processor, args)
    else:
        test_engine(model, processor, args)


def train_engine(model, processor, args):
    """ è®­ç»ƒå¼•æ“ """
    # === 1. æ•°æ®å‡†å¤‡ ===
    dataset = GaitCIRDataset(
        json_path=cfg.TRAIN_JSON, 
        data_root=cfg.DATASET_ROOT, 
        split_config_path=cfg.SPLIT_CONFIG,
        dataset_name=cfg.DATASET_NAME, # ğŸ”¥ [ä¿®æ­£] å¿…ä¼ å‚æ•°
        mode='train', 
        max_frames=cfg.TRAIN_MAX_FRAMES, 
        use_features=cfg.USE_FEATURES,
        feature_root=cfg.FEATURE_ROOT,
        use_mask=cfg.USE_MASK
    )
    
    sampler = DistributedSampler(dataset, shuffle=True)
    collate_fn = get_collate_fn(processor, mode='train')
    loader = DataLoader(dataset, batch_size=cfg.BATCH_SIZE, sampler=sampler, shuffle=False,
                        num_workers=cfg.NUM_WORKERS, collate_fn=collate_fn, pin_memory=True)
    
    # === 2. ä¼˜åŒ–å™¨ ===
    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), 
                      lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY)
    loss_fn = nn.CrossEntropyLoss()
    cosine_loss_fn = lambda x, y: 1.0 - F.cosine_similarity(x, y).mean()
    
    scheduler = get_scheduler("cosine", optimizer, num_warmup_steps=cfg.WARMUP_STEPS, 
                              num_training_steps=len(loader) * cfg.EPOCHS)

    # === 3. è®­ç»ƒå¾ªç¯ ===
    if dist.get_rank() == 0:
        print(f"ğŸš€ [Engine] Start Training ({cfg.EPOCHS} Epochs)...")
        os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
        
    model.train()
    
    for epoch in range(cfg.EPOCHS):
        sampler.set_epoch(epoch)
        
        total_loss = 0
        
        header = f"ğŸš€ Train Ep {epoch+1}/{cfg.EPOCHS}"
        iterator = tqdm(loader, desc=header) if dist.get_rank() == 0 else loader
        
        for batch in iterator:
            if batch is None: continue
            
            ref, tar, txt_ids, txt_mask, inv_ids, inv_mask = batch
            
            txt_ids, txt_mask = txt_ids.to(cfg.DEVICE), txt_mask.to(cfg.DEVICE)
            inv_ids, inv_mask = inv_ids.to(cfg.DEVICE), inv_mask.to(cfg.DEVICE)
            
            if cfg.USE_FEATURES:
                ref, tar = ref.to(cfg.DEVICE), tar.to(cfg.DEVICE)
            else:
                B, T, C, H, W = ref.shape
                ref = ref.view(-1, C, H, W).to(cfg.DEVICE) 
                tar = tar.view(-1, C, H, W).to(cfg.DEVICE)
                
            optimizer.zero_grad()
            
            # Forward
            raw_model = model.module
            
            if cfg.USE_FEATURES:
                ref_agg = raw_model.aggregate_features(ref, ref.size(0), ref.size(1))
                tar_agg = raw_model.aggregate_features(tar, tar.size(0), tar.size(1))
            else:
                ref_feat = raw_model.extract_img_feature(ref)
                tar_feat = raw_model.extract_img_feature(tar)
                ref_agg = raw_model.aggregate_features(ref_feat, B, T)
                tar_agg = raw_model.aggregate_features(tar_feat, B, T)

            txt_feat = raw_model.extract_txt_feature(txt_ids, txt_mask)
            inv_feat = raw_model.extract_txt_feature(inv_ids, inv_mask)
            
            q_fwd = raw_model.combiner(ref_agg, txt_feat) 
            q_inv = raw_model.combiner(tar_agg, inv_feat) 
            
            # Loss
            logit_scale = raw_model.logit_scale.exp()
            labels = torch.arange(len(q_fwd)).to(cfg.DEVICE)
            
            logits_fwd = (q_fwd @ tar_agg.T) * logit_scale
            loss_fwd = loss_fn(logits_fwd, labels)
            
            if cfg.LOSS_INV_TYPE == 'nce':
                logits_inv = (q_inv @ ref_agg.T) * logit_scale
                loss_inv = loss_fn(logits_inv, labels)
            else:
                loss_inv = cosine_loss_fn(q_inv, ref_agg)
            
            loss = loss_fwd + cfg.LOSS_ALPHA * loss_inv
            
            loss.backward()
            optimizer.step()
            scheduler.step()
            
            total_loss += loss.item()
            
            if dist.get_rank() == 0:
                current_lr = optimizer.param_groups[0]['lr']
                iterator.set_postfix({
                    "L": f"{loss.item():.4f}", 
                    "Lf": f"{loss_fwd.item():.3f}", 
                    "Li": f"{loss_inv.item():.3f}",
                    "LR": f"{current_lr:.1e}"
                })
        
        # Epoch End
        if dist.get_rank() == 0:
            avg_loss = total_loss / len(loader)
            print(f"âœ… Epoch {epoch+1}/{cfg.EPOCHS} Done. Avg Loss: {avg_loss:.4f}")
            
            save_path = os.path.join(cfg.OUTPUT_DIR, f"combiner_ep{epoch+1}.pth")
            torch.save(model.module.combiner.state_dict(), save_path)

def print_report(metrics):
    """
    æ‰“å°è¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Šè¡¨æ ¼ (ä»¿ Test.py é£æ ¼ + mAP)
    """
    print("\n" + "="*95)
    # è¡¨å¤´å¢åŠ  mAP
    print(f"{'Task Type':<20} | {'Metric':<8} | {'R@1':<6} | {'R@5':<6} | {'R@10':<6} | {'mAP':<6}")
    print("-" * 95)
    
    # å®šä¹‰ä»»åŠ¡æ˜¾ç¤ºé¡ºåº
    order = ["attribute_change", "viewpoint_change", "Overall"]
    
    for task in order:
        if task in metrics:
            res = metrics[task]
            count = res['Count']
            print(f"{task:<20} (N={count})")
            
            # 1. Strict æŒ‡æ ‡ (æœ€é‡è¦)
            s = res['Strict']
            print(f"  {'':<20} | {'Strict':<8} | {s['R1']:>6.1f} | {s['R5']:>6.1f} | {s['R10']:>6.1f} | {s['mAP']:>6.1f}")
            
            # 2. Soft æŒ‡æ ‡ (å®½æ¾åŒ¹é…)
            if 'Soft' in res:
                so = res['Soft']
                print(f"  {'':<20} | {'Soft':<8} | {so['R1']:>6.1f} | {so['R5']:>6.1f} | {so['R10']:>6.1f} | {so['mAP']:>6.1f}")
            
            # 3. ID æŒ‡æ ‡ (æ˜¯å¦æ‰¾å¯¹äº†äºº)
            if 'ID' in res:
                i = res['ID']
                print(f"  {'':<20} | {'ID-Only':<8} | {i['R1']:>6.1f} | {i['R5']:>6.1f} | {i['R10']:>6.1f} | {i['mAP']:>6.1f}")
            
            print("-" * 40)
            
    print("="*95 + "\n")


@torch.no_grad()
def test_engine(model, processor, args):
    """ æµ‹è¯•å¼•æ“ """
    if dist.get_rank() == 0: print("ğŸ” [Engine] Start Testing...")
    model.eval()
    
    dataset = GaitCIRDataset(
        json_path=cfg.TRAIN_JSON, 
        data_root=cfg.DATASET_ROOT, 
        split_config_path=cfg.SPLIT_CONFIG,
        dataset_name=cfg.DATASET_NAME, # ğŸ”¥ [ä¿®æ­£] å¿…ä¼ å‚æ•°ï¼Œç”¨äºå¤„ç†ä¸åŒæ•°æ®é›†è·¯å¾„é€»è¾‘
        mode='test', 
        max_frames=cfg.TEST_MAX_FRAMES, 
        use_features=cfg.USE_FEATURES,
        feature_root=cfg.FEATURE_ROOT,
        use_mask=cfg.USE_MASK
    )
    
    sampler = DistributedSampler(dataset, shuffle=False)
    collate_fn = get_collate_fn(processor, mode='test')
    loader = DataLoader(dataset, batch_size=cfg.BATCH_SIZE, sampler=sampler, 
                        num_workers=cfg.NUM_WORKERS, collate_fn=collate_fn)
    
    all_q, all_t = [], []
    all_meta, all_tasks = [], []
    
    iterator = tqdm(loader, desc="ğŸ” Testing") if dist.get_rank() == 0 else loader
    
    for batch in iterator:
        if batch is None: continue
        ref, tar, ids, mask, tasks, meta = batch
        
        # 1. æ–‡æœ¬æ•°æ®
        ids, mask = ids.to(cfg.DEVICE), mask.to(cfg.DEVICE)
        
        # è·å–åŸå§‹æ¨¡å‹ (è§£å¼€ DDP åŒ…è£…)
        raw_model = model.module if hasattr(model, 'module') else model
        
        # 2. è§†è§‰æ•°æ®å¤„ç† (å…¼å®¹ Feature / Image)
        if cfg.USE_FEATURES:
            # ç‰¹å¾æ¨¡å¼: [T, 512]
            if isinstance(ref, list):
                ref_agg_list = []
                tar_agg_list = []
                
                # é€ä¸ªæ ·æœ¬å¤„ç† (å¤„ç†å˜é•¿åºåˆ—)
                for r, t in zip(ref, tar):
                    r = r.to(cfg.DEVICE)
                    t = t.to(cfg.DEVICE)
                    
                    # èšåˆ: [T, 512] -> [1, T, 512] -> [1, 512]
                    r_agg = raw_model.aggregate_features(r.unsqueeze(0), 1, r.size(0))
                    t_agg = raw_model.aggregate_features(t.unsqueeze(0), 1, t.size(0))
                    
                    ref_agg_list.append(r_agg)
                    tar_agg_list.append(t_agg)
                
                # é‡æ–°å †å ä¸º Batch [B, 512]
                ref_agg = torch.cat(ref_agg_list, dim=0)
                tar_agg = torch.cat(tar_agg_list, dim=0)
            else:
                # å…œåº•ï¼šå¦‚æœæ˜¯ Tensor
                ref, tar = ref.to(cfg.DEVICE), tar.to(cfg.DEVICE)
                ref_agg = raw_model.aggregate_features(ref, ref.size(0), ref.size(1))
                tar_agg = raw_model.aggregate_features(tar, tar.size(0), tar.size(1))
        else:
            # ğŸ”¥ [ä¿®æ­£] Image Mode (Raw RGB): [B, T, C, H, W]
            ref = ref.to(cfg.DEVICE)
            tar = tar.to(cfg.DEVICE)
            
            # å¤„ç† Reference
            B_r, T_r, C, H, W = ref.shape
            ref_flat = ref.view(-1, C, H, W)
            ref_feat = raw_model.extract_img_feature(ref_flat) # [B*T, 512]
            ref_agg = raw_model.aggregate_features(ref_feat, B_r, T_r) # [B, 512]
            
            # å¤„ç† Target
            B_t, T_t, _, _, _ = tar.shape
            tar_flat = tar.view(-1, C, H, W)
            tar_feat = raw_model.extract_img_feature(tar_flat)
            tar_agg = raw_model.aggregate_features(tar_feat, B_t, T_t)

        # 3. æ–‡æœ¬ç‰¹å¾
        txt_f = raw_model.extract_txt_feature(ids, mask)
        
        # 4. èåˆ
        q_f = raw_model.combiner(ref_agg, txt_f)
        
        all_q.append(q_f.cpu())
        all_t.append(tar_agg.cpu())
        all_tasks.extend(tasks)
        all_meta.extend(meta)
        
    all_q = torch.cat(all_q, dim=0)
    all_t = torch.cat(all_t, dim=0)
    
    if dist.get_rank() == 0:
        print(f"ğŸ“Š Computing Metrics (Rank 0 Data Size: {len(all_q)})...")
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = compute_hierarchical_metrics(all_q, all_t, all_meta, all_meta, all_tasks)
        
        # æ‰“å°æŠ¥è¡¨
        print_report(metrics)

if __name__ == '__main__':
    parser = get_parser()
    args = parser.parse_args()
    
    initialization(args)
    run_model(args)