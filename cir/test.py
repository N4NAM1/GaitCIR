import torch
import os
from tqdm import tqdm
from torch.utils.data import DataLoader
# è®¾ç½® HF é•œåƒ (å¦‚æœéœ€è¦çš„è¯ï¼Œå»ºè®®ä¿ç•™åœ¨å…¥å£è„šæœ¬æˆ–ç¯å¢ƒå˜é‡ä¸­)
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
from transformers import CLIPProcessor

import config as cfg 
from modeling.demo_model import GaitCIRModel
from data.dataset_loader import GaitCIRDataset
from data.collate import get_collate_fn
from utils.Metrics import compute_hierarchical_metrics

# æ˜¾å¼æŒ‡å®šæµ‹è¯•å“ªä¸ªæƒé‡ (æ–¹ä¾¿æ¶ˆèå®éªŒå¯¹æ¯”)
TEST_CHECKPOINT = "./checkpoints/cycle_on/L_cycle_combiner_ep30.pth"

@torch.no_grad()
def evaluate():
    print(f"ğŸš€ Loading Model from: {TEST_CHECKPOINT}")
    
    # 1. æ¨¡å‹åŠ è½½
    model = GaitCIRModel(cfg.MODEL_ID).to(cfg.DEVICE)
    if os.path.exists(TEST_CHECKPOINT):
        state_dict = torch.load(TEST_CHECKPOINT)
        model.combiner.load_state_dict(state_dict)
        print("âœ… æƒé‡åŠ è½½æˆåŠŸ!")
    else:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ {TEST_CHECKPOINT}")
        return # é€€å‡º

    model.eval()
    processor = CLIPProcessor.from_pretrained(cfg.MODEL_ID)
    
    # 2. æ•°æ®åŠ è½½ (Mode='test')
    # collate_fn è¿”å›: ref_stack, tar_stack, input_ids, attention_mask, tasks, meta
    collate_fn = get_collate_fn(processor, mode='test')

    dataset = GaitCIRDataset(
        json_path=cfg.TRAIN_JSON,       
        data_root=cfg.DATASET_ROOT,
        split_config_path=cfg.SPLIT_CONFIG,
        mode='test',                    
        max_frames=cfg.NUM_FRAMES if hasattr(cfg, 'NUM_FRAMES') else 8, 
        subject_token="the person"
    )

    loader = DataLoader(dataset, batch_size=cfg.BATCH_SIZE, shuffle=False, 
                        num_workers=cfg.NUM_WORKERS, collate_fn=collate_fn)

    all_q, all_t = [], []
    all_meta, all_tasks = [], []
    
    print(f"ğŸ” å¼€å§‹æµ‹è¯• (N={len(dataset)})...")
    
    # æ³¨æ„ï¼šè¿™é‡Œå˜é‡æ•°é‡å¿…é¡»å’Œ collate.py çš„ test æ¨¡å¼è¿”å›ä¸€è‡´ (6ä¸ª)
    for ref, tar, ids, mask, tasks, meta in tqdm(loader):
        B, T, C, H, W = ref.shape
        
        # å±•å¹³å¤„ç†å¤šå¸§
        ref = ref.view(B*T, C, H, W).to(cfg.DEVICE)
        tar = tar.view(B*T, C, H, W).to(cfg.DEVICE)
        ids = ids.to(cfg.DEVICE)
        mask = mask.to(cfg.DEVICE)
        
        with torch.cuda.amp.autocast():
            # ç‰¹å¾æå–
            ref_f = model.extract_img_feature(ref) # [B*T, 512]
            tar_f = model.extract_img_feature(tar)
            
            # å¹³å‡æ± åŒ–èšåˆå¤šå¸§ç‰¹å¾ [B*T, 512] -> [B, 512]
            ref_f = ref_f.view(B, T, -1).mean(dim=1)
            tar_f = tar_f.view(B, T, -1).mean(dim=1)
            
            # å½’ä¸€åŒ– (Mean ä¹‹åéœ€è¦é‡æ–°å½’ä¸€åŒ–)
            ref_f = torch.nn.functional.normalize(ref_f, dim=-1)
            tar_f = torch.nn.functional.normalize(tar_f, dim=-1)
            
            txt_f = model.extract_txt_feature(ids, mask)
            
            # Combiner èåˆ
            # è¿™é‡Œç›´æ¥è°ƒç”¨ combiner å¾—åˆ° raw featureï¼Œä¹Ÿå¯ä»¥åƒ forward é‚£æ ·å†æ¬¡å½’ä¸€åŒ–
            q_f_raw = model.combiner(ref_f, txt_f)
            q_f = torch.nn.functional.normalize(q_f_raw, dim=-1)
        
        all_q.append(q_f.float().cpu())
        all_t.append(tar_f.float().cpu())
        all_tasks.extend(tasks)
        all_meta.extend(meta)
        
    all_q = torch.cat(all_q, dim=0)
    all_t = torch.cat(all_t, dim=0)
    
    # 3. æŒ‡æ ‡è®¡ç®—
    metrics = compute_hierarchical_metrics(all_q, all_t, all_meta, all_meta, all_tasks)
    
    # æ‰“å°ç»“æœ (ä¿æŒåŸæœ‰æ ¼å¼)
    print_metrics(metrics)

def print_metrics(metrics):
    print("\n" + "="*85)
    print(f"{'Task Type':<20} | {'Metric':<8} | {'R@1':<6} | {'R@5':<6} | {'R@10':<6}")
    print("-" * 85)
    order = ["attribute_change", "viewpoint_change", "composite_change", "Overall"]
    for task in order:
        if task in metrics:
            res = metrics[task]
            print(f"{task:<20} ({res['Count']})")
            s = res['Strict']
            print(f"  {'':<20} | {'Strict':<8} | {s['R1']:.1f}   | {s['R5']:.1f}   | {s['R10']:.1f}")
            so = res['Soft']
            print(f"  {'':<20} | {'Soft':<8} | {so['R1']:.1f}   | {so['R5']:.1f}   | -")
            i = res['ID']
            print(f"  {'':<20} | {'ID-Only':<8} | {i['R1']:.1f}   | {i['R5']:.1f}   | -")
            print("-" * 40)
    print("="*85)

if __name__ == '__main__':
    evaluate()