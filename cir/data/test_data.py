import torch
import os
from torch.utils.data import DataLoader
from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor
from dataset_loader import GaitCIRDataset
import matplotlib.pyplot as plt

# æ¨¡æ‹Ÿ CLIP çš„é¢„å¤„ç† (ä¸å¸¦ Normalize ä»¥ä¾¿å¯è§†åŒ–)
simple_transform = Compose([
    Resize(224, interpolation=3),
    CenterCrop(224),
    ToTensor(),
])

def test():
    print("ğŸš€ å¼€å§‹ DataLoader å†’çƒŸæµ‹è¯•...")
    
    # ================= é…ç½®åŒºåŸŸ =================
    MASTER_JSON = '../../datasets/GaitCIR_RGB/casiab_cir_final.json'
    SPLIT_CONFIG = '../../datasets/GaitCIR_RGB/Split/CASIA-B.json'
    MODE = 'train' # æµ‹è¯•è®­ç»ƒé›†æ•°æ®
    
    # åˆå§‹åŒ– Dataset
    dataset = GaitCIRDataset(
        json_path=MASTER_JSON,
        data_root='../../datasets/CASIA-B-Processed',
        split_config_path=SPLIT_CONFIG, # ä¼ å…¥åˆ†å‰²é…ç½®
        mode=MODE,                      # æŒ‡å®šæ¨¡å¼
        max_frames=1,                   # è®­ç»ƒæ¨¡å¼ä¸‹åªé‡‡å•å¸§
        transform=simple_transform,
        subject_token="the person",
        return_static=True              # å¿…é¡»ä¸º True æ‰èƒ½æ‰“å°é™æ€æè¿°
    )
    
    loader = DataLoader(dataset, batch_size=4, shuffle=True)
    
    # è¯»å–ä¸€ä¸ª Batch
    try:
        batch = next(iter(loader))
    except Exception as e:
        print(f"âŒ DataLoader è¯»å–å¤±è´¥: {e}")
        return

    # --- æ‰“å°è°ƒè¯•ä¿¡æ¯ ---
    print("\n" + "="*40)
    print(f"ğŸ” Batch Keys: {list(batch.keys())}")
    
    # æ£€æŸ¥å½¢çŠ¶
    # è®­ç»ƒæ¨¡å¼ä¸‹åº”è¯¥æ˜¯ [4, 3, 224, 224]
    # æµ‹è¯•æ¨¡å¼ä¸‹åº”è¯¥æ˜¯ [4, 8, 3, 224, 224] (List of Tensors æˆ– Stacked Tensor)
    ref_data = batch['ref_imgs']
    if isinstance(ref_data, list):
        print(f"ğŸ–¼ï¸ Ref Image (List): Length {len(ref_data)}, Item Shape {ref_data[0].shape}")
        #å¦‚æœæ˜¯åˆ—è¡¨å–ç¬¬ä¸€å¸§ç”¨äºå¯è§†åŒ–
        ref_tensor = ref_data[0]
        tar_tensor = batch['tar_imgs'][0]
    else:
        print(f"ğŸ–¼ï¸ Ref Image (Tensor): Shape {ref_data.shape}")
        ref_tensor = batch['ref_imgs'][0]
        tar_tensor = batch['tar_imgs'][0]

    print("-" * 40)
    
    # æ‰“å°æ–‡æœ¬ (æ£€æŸ¥å ä½ç¬¦æ›¿æ¢)
    print(f"ğŸ“ Instruction: {batch['text'][0]}")
    print(f"ğŸ“ Instruction_inv: {batch['text_inv'][0]}")
    
    # æ£€æŸ¥é™æ€æè¿°æ˜¯å¦å­˜åœ¨
    if 'ref_text' in batch:
        print(f"ğŸ·ï¸ Ref Static:  {batch['ref_text'][0]}")
        print(f"ğŸ·ï¸ Tar Static:  {batch['tar_text'][0]}")
    else:
        print("âš ï¸ Warning: 'ref_text' not found. Did you set return_static=True?")
        
    print(f"ğŸ“Œ Task Type:   {batch['task'][0]}")
    print(f"ğŸ†” Subject ID:  {batch.get('sid', 'N/A')[0]}")
    print(f"ğŸ¨ Condition:   {batch.get('cond', 'N/A')[0]}")
    print("-" * 40)
    
    # --- å¯è§†åŒ–æ£€æŸ¥ ---
    # Tensor (C, H, W) -> Numpy (H, W, C)
    ref_img = ref_tensor.permute(1, 2, 0).numpy()
    tar_img = tar_tensor.permute(1, 2, 0).numpy()
    
    plt.figure(figsize=(12, 6))
    
    plt.subplot(1, 2, 1)
    plt.title(f"Ref: {batch['text'][0][:30]}...")
    plt.imshow(ref_img)
    plt.axis('off')
    
    plt.subplot(1, 2, 2)
    plt.title(f"Target\n(Should match instruction)")
    plt.imshow(tar_img)
    plt.axis('off')
    
    save_path = "loader_check.png"
    plt.savefig(save_path)
    print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜è‡³ {save_path}")
    print("   -> è¯·æ£€æŸ¥èƒŒæ™¯æ˜¯å¦ä¸ºå…¨é»‘ (Masked RGB)")
    print("   -> è¯·æ£€æŸ¥ Ref å’Œ Tar æ˜¯å¦ç¬¦åˆæ–‡æœ¬æè¿°")

if __name__ == '__main__':
    test()