import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import CLIPModel

class Combiner(nn.Module):
    """
    è½»é‡çº§èžåˆç½‘ç»œï¼šæŽ¥æ”¶ (Image_Feat, Text_Feat)ï¼Œè¾“å‡º Query_Feat
    """
    def __init__(self, input_dim=512, hidden_dim=2048):
        super().__init__()
        self.input_dim = input_dim * 2 
        
        self.layers = nn.Sequential(
            nn.Linear(self.input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.5), 
            nn.Linear(hidden_dim, input_dim) 
        )
        
        # æ®‹å·®ç³»æ•°
        self.alpha = nn.Parameter(torch.tensor(0.0))

    def forward(self, img_feat, txt_feat):
        combined = torch.cat((img_feat, txt_feat), dim=-1)
        delta = self.layers(combined)
        # Residual Connection
        output = img_feat + self.alpha * delta
        return F.normalize(output, dim=-1)

class GaitCIRModel(nn.Module):
    def __init__(self, model_id="openai/clip-vit-base-patch32"):
        super().__init__()
        print(f"Loading CLIP: {model_id}...")
        self.clip = CLIPModel.from_pretrained(model_id)
        
        # â„ï¸ å†»ç»“ CLIP è§†è§‰å’Œæ–‡æœ¬éƒ¨åˆ†ï¼Œåªè®­ç»ƒ Combiner
        for param in self.clip.parameters():
            param.requires_grad = False
            
        # åˆå§‹åŒ–ç»„ä»¶
        self.feature_dim = self.clip.projection_dim # 512
        self.combiner = Combiner(self.feature_dim)
        
        # å¯å­¦ä¹ çš„æ¸©åº¦ç³»æ•°
        self.logit_scale = nn.Parameter(torch.ones([]) * 2.6592)

    def extract_img_feature(self, pixel_values):
        """ å•å¸§ç‰¹å¾æå–: [N, 3, H, W] -> [N, 512] """
        with torch.no_grad():
            feat = self.clip.get_image_features(pixel_values)
        return F.normalize(feat, dim=-1)

    def extract_txt_feature(self, input_ids, attention_mask):
        """ æ–‡æœ¬ç‰¹å¾æå–: [B, L] -> [B, 512] """
        with torch.no_grad():
            feat = self.clip.get_text_features(input_ids, attention_mask)
        return F.normalize(feat, dim=-1)

    def aggregate_features(self, inputs, batch_size, frames_num):
        """
        ðŸ”¥ æ ¸å¿ƒå‡çº§ï¼šGaitSet é£Žæ ¼çš„æ—¶åºèšåˆ (Set Pooling)
        æ”¯æŒè¾“å…¥ 'Image Tensor' æˆ– 'Feature Tensor'ï¼Œè‡ªåŠ¨å¤„ç†ã€‚
        """
        # 1. å¦‚æžœè¾“å…¥æ˜¯å›¾ç‰‡ [B*T, 3, H, W]ï¼Œå…ˆæå–ç‰¹å¾
        if inputs.dim() == 4:
            features = self.extract_img_feature(inputs) # -> [B*T, 512]
        else:
            features = inputs # å·²ç»æ˜¯ [B*T, 512] æˆ– [B, T, 512]

        # 2. ç»Ÿä¸€ç»´åº¦ -> [B, T, D]
        if features.dim() == 2:
            features = features.view(batch_size, frames_num, -1)
            
        # 3. Max Pooling (GaitSet ä¹Ÿæ˜¯ç”¨çš„ Max)
        # max() è¿”å›ž (values, indices)ï¼Œæˆ‘ä»¬éœ€è¦ values
        agg_feat = features.max(dim=1)[0] # -> [B, 512]
        
        # 4. âš ï¸ å†æ¬¡å½’ä¸€åŒ– (Pooling åŽæ¨¡é•¿ä¼šå˜ï¼Œå¿…é¡» Re-Norm)
        agg_feat = F.normalize(agg_feat, dim=-1)
        
        return agg_feat

    def forward(self, ref_input, input_ids, attention_mask):
        """
        è®­ç»ƒå‰å‘ä¼ æ’­ï¼šè®¡ç®— Query Embedding
        è‡ªåŠ¨åˆ¤æ–­ ref_input æ˜¯å›¾ç‰‡è¿˜æ˜¯ç‰¹å¾
        """
        batch_size = input_ids.size(0)
        
        # === 1. è§†è§‰å¤„ç† (Extract + Aggregate) ===
        if ref_input.dim() == 4:
            # Image Mode: [N, 3, H, W] -> éœ€è¦è®¡ç®— T
            total_imgs = ref_input.size(0)
            frames_num = total_imgs // batch_size
            ref_agg = self.aggregate_features(ref_input, batch_size, frames_num)
            
        elif ref_input.dim() == 3:
            # Feature Mode: [B, T, D]
            frames_num = ref_input.size(1)
            ref_agg = self.aggregate_features(ref_input, batch_size, frames_num)
            
        else:
            raise ValueError(f"Unknown input shape: {ref_input.shape}")

        # === 2. æ–‡æœ¬å¤„ç† ===
        txt_feat = self.extract_txt_feature(input_ids, attention_mask)
        
        # === 3. èžåˆ (Ref + Text -> Query) ===
        query_feat = self.combiner(ref_agg, txt_feat)
        
        # è¾“å‡ºå½’ä¸€åŒ–
        return query_feat