import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader

from tqdm import tqdm
import os

# 1. ç¯å¢ƒé…ç½®
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
# è¿™é‡Œçš„ cv2 è®¾ç½®å»ºè®®æ”¾åœ¨ dataset_loader æˆ– __init__ é‡Œï¼Œä¸è¿‡æ”¾åœ¨è¿™ä¹Ÿè¡Œ
from transformers import CLIPProcessor
import cv2
cv2.setNumThreads(0)
cv2.ocl.setUseOpenCL(False)

# 2. å¼•å…¥æ ¸å¿ƒæ¨¡å—
import config as cfg  # å¼•å…¥å…¨å±€é…ç½® (æ¨è)
from modeling.demo_model import GaitCIRModel
from data.dataset_loader import GaitCIRDataset
from utils.Metrics import compute_hierarchical_metrics
from data.collate import get_collate_fn

# ================= æœ¬åœ°é…ç½® (å¦‚æœä¸ä½¿ç”¨ cfgï¼Œå¯å–æ¶ˆæ³¨é‡Šè¦†ç›–) =================
# TEST_JSON = './datasets/GaitCIR_RGB/casiab_cir_test_split.json'
# SPLIT_CONFIG = './datasets/GaitCIR_RGB/casiab_split_config.json'
# DATA_ROOT = './datasets/CASIA-B-Processed'
# CHECKPOINT = './outputs/checkpoints/combiner_ep15.pth' 
# BATCH_SIZE = 32
# NUM_FRAMES = 8 
# NUM_WORKERS = 4
# DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# =========================================================================

@torch.no_grad()
def evaluate():
    # ä½¿ç”¨ config ä¸­çš„å˜é‡ (å¦‚æœæ²¡ç”¨ config.pyï¼Œè¯·æ›¿æ¢ä¸ºä¸Šé¢çš„æœ¬åœ°å˜é‡)
    checkpoint_path = cfg.OUTPUT_DIR + "/combiner_ep15.pth" # æˆ–è€…ç›´æ¥ç”¨ä¸Šé¢çš„ CHECKPOINT
    
    print(f"ğŸš€ Loading Model from: {checkpoint_path}")
    model = GaitCIRModel(cfg.MODEL_ID).to(cfg.DEVICE)
    
    if os.path.exists(checkpoint_path):
        state_dict = torch.load(checkpoint_path)
        model.combiner.load_state_dict(state_dict)
        print("âœ… æƒé‡åŠ è½½æˆåŠŸ!")
    else:
        print(f"âŒ è­¦å‘Š: æ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ï¼Œå°†ä½¿ç”¨éšæœºåˆå§‹åŒ–æµ‹è¯•ï¼")
        
    model.eval()

    # å‡†å¤‡å¤„ç†å™¨
    processor = CLIPProcessor.from_pretrained(cfg.MODEL_ID)
    
    # è·å–æµ‹è¯•ä¸“ç”¨çš„ Collate Fn (æ”¯æŒ List[Tensor] å †å å’Œå…ƒæ•°æ®ä¼ é€’)
    collate_fn = get_collate_fn(processor, mode='test')

    # åˆå§‹åŒ– Dataset
    print(f"Loading Test Dataset...")
    dataset = GaitCIRDataset(
        json_path=cfg.TRAIN_JSON,       # æ³¨æ„ï¼šè¿™é‡Œé€šå¸¸ä¼ å…¥ Master JSON
        data_root=cfg.DATASET_ROOT,
        split_config_path=cfg.SPLIT_CONFIG,
        mode='test',                    # æŒ‡å®šæµ‹è¯•æ¨¡å¼
        max_frames=cfg.NUM_FRAMES if hasattr(cfg, 'NUM_FRAMES') else 8, # æµ‹è¯•æ—¶é‡‡æ ·å¤šå¸§
        subject_token="the person"
    )

    loader = DataLoader(
        dataset, 
        batch_size=cfg.BATCH_SIZE, 
        shuffle=False, 
        num_workers=cfg.NUM_WORKERS, 
        collate_fn=collate_fn
    )

    all_q, all_t = [], []
    all_meta, all_tasks = [], []
    
    print(f"ğŸ” å¼€å§‹ç‰¹å¾æå– (Test Set Size: {len(dataset)})...")
    
    for ref, tar, ids, mask, tasks, meta in tqdm(loader):
        # Ref/Tar Shape: [B, T, C, H, W]
        B, T, C, H, W = ref.shape
        
        ref = ref.view(B*T, C, H, W).to(cfg.DEVICE)
        tar = tar.view(B*T, C, H, W).to(cfg.DEVICE)
        ids = ids.to(cfg.DEVICE)
        mask = mask.to(cfg.DEVICE)
        
        with torch.cuda.amp.autocast():
            # 1. æå– Frame ç‰¹å¾
            ref_f = model.extract_img_feature(ref).view(B, T, -1).mean(dim=1)
            tar_f = model.extract_img_feature(tar).view(B, T, -1).mean(dim=1)
            
            # 2. æå–æ–‡æœ¬
            txt_f = model.extract_txt_feature(ids, mask)
            
            # 3. èåˆ
            q_f = model.combiner(ref_f, txt_f)
        
        all_q.append(q_f.float().cpu())
        all_t.append(tar_f.float().cpu())
        all_tasks.extend(tasks)
        all_meta.extend(meta)
        
    all_q = torch.cat(all_q, dim=0)
    all_t = torch.cat(all_t, dim=0)
    
    print(f"âœ… ç‰¹å¾æå–å®Œæˆã€‚Query Shape: {all_q.shape}")
    
    # è®¡ç®—åˆ†å±‚æŒ‡æ ‡ (è°ƒç”¨ utils)
    metrics = compute_hierarchical_metrics(all_q, all_t, all_meta, all_meta, all_tasks)
    
    # æ‰“å°æŠ¥è¡¨
    print("\n" + "="*85)
    print(f"{'Task Type':<20} | {'Metric':<8} | {'R@1':<6} | {'R@5':<6} | {'R@10':<6}")
    print("-" * 85)
    
    order = ["attribute_change", "viewpoint_change", "composite_change", "Overall"]
    
    for task in order:
        if task in metrics:
            res = metrics[task]
            print(f"{task:<20} ({res['Count']})")
            
            s = res['Strict']
            print(f"  {'':<20} | {'Strict':<8} | {s['R1']:.1f}   | {s['R5']:.1f}   | {s['R10']:.1f}")
            
            so = res['Soft']
            print(f"  {'':<20} | {'Soft':<8} | {so['R1']:.1f}   | {so['R5']:.1f}   | -")
            
            i = res['ID']
            print(f"  {'':<20} | {'ID-Only':<8} | {i['R1']:.1f}   | {i['R5']:.1f}   | -")
            print("-" * 40)
            
    print("="*85)

if __name__ == '__main__':
    evaluate()