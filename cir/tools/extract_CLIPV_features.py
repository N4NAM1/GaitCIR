import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

import json
import torch
import cv2
import numpy as np
from PIL import Image
from tqdm import tqdm
from transformers import CLIPProcessor

# å¼•å…¥é¡¹ç›®é…ç½®
import sys
sys.path.append(os.getcwd()) 
from cir.modeling.demo_model import GaitCIRModel
import cir.config as cfg

# ================= âš™ï¸ æ ¸å¿ƒé…ç½®åŒºåŸŸ =================
# ã€å¼€å…³ã€‘True = å»é™¤èƒŒæ™¯(å˜é»‘); False = ä¿ç•™åŸå›¾èƒŒæ™¯
USE_MASK = True  

# è¾“å…¥è·¯å¾„
DATA_ROOT = cfg.DATASET_ROOT
RGB_ROOT = os.path.join(DATA_ROOT, 'RGB')
MASK_ROOT = os.path.join(DATA_ROOT, 'Mask')
JSON_PATH = cfg.TRAIN_JSON 

# è¾“å‡ºè·¯å¾„ï¼šè‡ªåŠ¨æ ¹æ®å¼€å…³å†³å®šå­˜å“ªé‡Œï¼Œé¿å…æ··æ·†
if USE_MASK:
    OUTPUT_ROOT = '/root/autodl-tmp/CASIA-B-Processed/CLIP_feature_Masked'
    print("ğŸ­ Mode: MASKED (Background removed)")
else:
    OUTPUT_ROOT = '/root/autodl-tmp/CASIA-B-Processed/CLIP_feature'
    print("ğŸ–¼ï¸ Mode: UNMASKED (Original background kept)")

# å…¶ä»–å‚æ•°
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# ==================================================

def load_and_preprocess_frames(seq_path, processor):
    full_seq_dir = os.path.join(RGB_ROOT, seq_path)
    if not os.path.isdir(full_seq_dir): return None

    frame_names = sorted([f for f in os.listdir(full_seq_dir) if f.endswith('.jpg')])
    if not frame_names: return None

    images = []
    for frame_name in frame_names:
        # 1. è¯»å– RGB
        rgb_path = os.path.join(full_seq_dir, frame_name)
        rgb_img = cv2.imread(rgb_path)
        if rgb_img is None: continue
        rgb_img = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2RGB)

        # 2. ã€å…³é”®é€»è¾‘ã€‘æ ¹æ®å¼€å…³å†³å®šæ˜¯å¦åº”ç”¨ Mask
        if USE_MASK:
            mask_name = frame_name.replace('.jpg', '.png')
            mask_path = os.path.join(MASK_ROOT, seq_path, mask_name)
            if os.path.exists(mask_path):
                mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                _, mask_img = cv2.threshold(mask_img, 127, 255, cv2.THRESH_BINARY)
                mask_img = mask_img.astype(np.float32) / 255.0
                mask_img = mask_img[:, :, np.newaxis]
                # èåˆï¼šèƒŒæ™¯å˜é»‘
                rgb_img = (rgb_img * mask_img).astype(np.uint8)
        
        images.append(Image.fromarray(rgb_img))

    if not images: return None

    inputs = processor(images=images, return_tensors="pt")
    return inputs['pixel_values']

@torch.no_grad()
def main():
    os.makedirs(OUTPUT_ROOT, exist_ok=True)

    # åŠ è½½æ¨¡å‹
    print(f"ğŸš€ Loading Model: {cfg.MODEL_ID}")
    model = GaitCIRModel(cfg.MODEL_ID).to(DEVICE)
    model.eval()
    processor = CLIPProcessor.from_pretrained(cfg.MODEL_ID)

    # è¯»å– JSON è·å–åºåˆ—åˆ—è¡¨
    print(f"ğŸ“‚ Scanning JSON: {JSON_PATH}")
    with open(JSON_PATH, 'r') as f:
        data = json.load(f)
    
    unique_seqs = set()
    for item in data:
        unique_seqs.add(item['ref']['seq_path'])
        unique_seqs.add(item['tar']['seq_path'])
    
    sorted_seqs = sorted(list(unique_seqs))
    print(f"âœ… Found {len(sorted_seqs)} unique sequences.")
    print(f"ğŸ’¾ Saving to: {OUTPUT_ROOT}")

    # å¼€å§‹æå–
    for seq_path in tqdm(sorted_seqs):
        save_path = os.path.join(OUTPUT_ROOT, seq_path + ".pt")
        save_dir = os.path.dirname(save_path)
        
        if os.path.exists(save_path): continue
            
        os.makedirs(save_dir, exist_ok=True)

        pixel_values = load_and_preprocess_frames(seq_path, processor)
        if pixel_values is None: continue
            
        pixel_values = pixel_values.to(DEVICE)
        feats = model.extract_img_feature(pixel_values)
        
        # å­˜ç›˜
        torch.save(feats.cpu(), save_path)

    print("ğŸ‰ Done!")

if __name__ == '__main__':
    main()