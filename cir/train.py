import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import os
# è®¾ç½® HF é•œåƒ (å¦‚æœéœ€è¦çš„è¯ï¼Œå»ºè®®ä¿ç•™åœ¨å…¥å£è„šæœ¬æˆ–ç¯å¢ƒå˜é‡ä¸­)
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import sys
from tqdm import tqdm
from transformers import CLIPProcessor, AdamW, get_scheduler

# === å¼•å…¥é…ç½®æ¨¡å— ===
import config as cfg

# å¼•å…¥ä½ çš„å…¶ä»–æ¨¡å—
from data.dataset_loader import GaitCIRDataset
from modeling.demo_model2 import GaitCIRModel
from data.collate import get_collate_fn

# ================= æœ¬åœ°è®­ç»ƒç‰¹å®šè¶…å‚ =================
# è¿™äº›å‚æ•°é€šå¸¸éšå®éªŒå˜åŒ–ï¼Œå¯ä»¥ä¿ç•™åœ¨æ­¤å¤„ï¼Œä¹Ÿå¯ä»¥ç§»å…¥ config
LR = 1e-4            
EPOCHS = 30

# === ã€æ¶ˆèå®éªŒé…ç½®ã€‘ ===
# ä¿®æ”¹æ­¤å¤„å¯å¿«é€Ÿè¿›è¡Œå¯¹æ¯”å®éªŒ
ABLATION_CONFIG = {
    "USE_CYCLE_LOSS": True,  # å¼€å…³ï¼šæ˜¯å¦ä½¿ç”¨å¾ªç¯ä¸€è‡´æ€§ Loss
    "CYCLE_LAMBDA": 1.0,     # æƒé‡ï¼šL_total = L_cir + lambda * L_cycle
}
# ===================================================

def train():
    # ä½¿ç”¨ config ä¸­çš„è¾“å‡ºè·¯å¾„
    # ä¸ºäº†åŒºåˆ†ä¸åŒå®éªŒï¼Œå»ºè®®åœ¨è¾“å‡ºè·¯å¾„ä¸­å¸¦ä¸Šæ˜¯å¦ä½¿ç”¨ Cycle çš„æ ‡è®°
    exp_sub_dir = "cycle_on" if ABLATION_CONFIG["USE_CYCLE_LOSS"] else "cycle_off"
    save_dir = os.path.join(cfg.OUTPUT_DIR, exp_sub_dir)
    os.makedirs(save_dir, exist_ok=True)
    
    print(f"ğŸš€ å®éªŒé…ç½®: {ABLATION_CONFIG}")
    print(f"ğŸ“‚ Checkpoints å°†ä¿å­˜è‡³: {save_dir}")

    # 1. å‡†å¤‡æ¨¡å‹
    print(f"ğŸš€ åˆå§‹åŒ–æ¨¡å‹: {cfg.MODEL_ID}")
    processor = CLIPProcessor.from_pretrained(cfg.MODEL_ID)
    model = GaitCIRModel(cfg.MODEL_ID).to(cfg.DEVICE)
    
    # ä¼˜åŒ–å™¨ï¼šåªè®­ç»ƒ Combiner å’Œ Logit Scale
    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=1e-4)
    
    # Loss å®šä¹‰
    loss_cir_fn = nn.CrossEntropyLoss()       # ç”¨äºæ­£å‘æ£€ç´¢ (InfoNCE)
    loss_cycle_fn = nn.CosineEmbeddingLoss()  # ç”¨äºå¾ªç¯é‡æ„ (Recon -> Ref)

    # 2. å‡†å¤‡æ•°æ®
    print(f"åŠ è½½è®­ç»ƒé›† (Batch Size: {cfg.BATCH_SIZE})...")
    dataset = GaitCIRDataset(
        json_path=cfg.TRAIN_JSON,       # ä½¿ç”¨ config ä¸­çš„è·¯å¾„
        data_root=cfg.DATASET_ROOT,    
        split_config_path=cfg.SPLIT_CONFIG, 
        mode='train', 
        max_frames=1, 
        subject_token="the person"
    )

    # è·å–è®­ç»ƒæ¨¡å¼çš„ collate_fn (ä¼šè¿”å› text_inv)
    collate_fn = get_collate_fn(processor, mode='train')

    loader = DataLoader(
        dataset, 
        batch_size=cfg.BATCH_SIZE, 
        shuffle=True, 
        num_workers=cfg.NUM_WORKERS, 
        collate_fn=collate_fn, 
        pin_memory=True
    )
    
    scheduler = get_scheduler("cosine", optimizer, num_warmup_steps=100, num_training_steps=len(loader)*EPOCHS)

    # 3. è®­ç»ƒå¾ªç¯
    print(f"å¼€å§‹è®­ç»ƒ... (æ€»æ­¥æ•°: {len(loader)*EPOCHS}) | è®¾å¤‡: {cfg.DEVICE}")
    
    for epoch in range(EPOCHS):
        model.train()
        
        # ç»Ÿè®¡å˜é‡
        total_loss_avg = 0
        cir_loss_avg = 0
        cycle_loss_avg = 0
        
        pbar = tqdm(loader, desc=f"Epoch {epoch+1}/{EPOCHS}")
        
        # æ³¨æ„ï¼šè¿™é‡Œè§£åŒ… 6 ä¸ªå˜é‡ (é€‚é…ä¿®æ”¹åçš„ collate.py)
        for ref_imgs, tar_imgs, fwd_ids, fwd_mask, inv_ids, inv_mask in pbar:
            
            # è½¬ç§»æ•°æ®åˆ°è®¾å¤‡
            ref_imgs = ref_imgs.to(cfg.DEVICE)
            tar_imgs = tar_imgs.to(cfg.DEVICE)
            fwd_ids = fwd_ids.to(cfg.DEVICE)
            fwd_mask = fwd_mask.to(cfg.DEVICE)
            inv_ids = inv_ids.to(cfg.DEVICE)
            inv_mask = inv_mask.to(cfg.DEVICE)
            
            optimizer.zero_grad()
            
            # === A. ç‰¹å¾æå– (Frozen CLIP) ===
            # ref_feat: [B, 512] (å·²å½’ä¸€åŒ–)
            ref_feat = model.extract_img_feature(ref_imgs)
            
            with torch.no_grad():
                # tar_feat: [B, 512] (å·²å½’ä¸€åŒ–)
                tar_feat = model.extract_img_feature(tar_imgs)
            
            # fwd_txt_feat: [B, 512] (å·²å½’ä¸€åŒ–)
            fwd_txt_feat = model.extract_txt_feature(fwd_ids, fwd_mask)
            
            # === B. æ­£å‘æ£€ç´¢è¿‡ç¨‹ (L_cir) ===
            # Ref + T_fwd -> Pred (Combiner å†…éƒ¨è¾“å‡ºæœªå½’ä¸€åŒ–ç‰¹å¾ï¼Œè¿™é‡Œæ‰‹åŠ¨å½’ä¸€åŒ–)
            pred_feat_raw = model.combiner(ref_feat, fwd_txt_feat)
            pred_feat = F.normalize(pred_feat_raw, dim=-1) 
            
            # è®¡ç®—å¯¹æ¯”æŸå¤± (Batch-based classification)
            logit_scale = model.logit_scale.exp()
            logits = (pred_feat @ tar_feat.T) * logit_scale
            labels = torch.arange(logits.size(0)).to(cfg.DEVICE)
            
            l_cir = loss_cir_fn(logits, labels)
            
            # === C. å¾ªç¯ä¸€è‡´æ€§è¿‡ç¨‹ (L_cycle) ===
            l_cycle = torch.tensor(0.0).to(cfg.DEVICE)
            
            if ABLATION_CONFIG["USE_CYCLE_LOSS"]:
                inv_txt_feat = model.extract_txt_feature(inv_ids, inv_mask)
                
                # Pred (Normalized) + T_inv -> Recon
                # æˆ‘ä»¬å¸Œæœ› Recon èƒ½å¤Ÿé‡æ„å‡ºåŸå§‹çš„ Ref ç‰¹å¾
                recon_feat_raw = model.combiner(pred_feat, inv_txt_feat)
                
                # Cosine Embedding Loss: 
                # Input1: recon, Input2: ref, Target: 1 (è¡¨ç¤ºå¸Œæœ›å®ƒä»¬ç›¸ä¼¼)
                target_ones = torch.ones(ref_feat.size(0)).to(cfg.DEVICE)
                l_cycle = loss_cycle_fn(recon_feat_raw, ref_feat, target_ones)

            # === D. æ€»æŸå¤± ===
            loss = l_cir + ABLATION_CONFIG["CYCLE_LAMBDA"] * l_cycle
            
            loss.backward()
            optimizer.step()
            scheduler.step()
            
            # è®°å½•æ•°æ®
            total_loss_avg += loss.item()
            cir_loss_avg += l_cir.item()
            cycle_loss_avg += l_cycle.item() if ABLATION_CONFIG["USE_CYCLE_LOSS"] else 0
            
            pbar.set_postfix({
                "Loss": f"{loss.item():.4f}", 
                "L_cir": f"{l_cir.item():.4f}",
                "L_cyc": f"{l_cycle.item():.4f}"
            })
        
        # Epoch ç»“æŸç»Ÿè®¡
        steps = len(loader)
        avg_loss = total_loss_avg / steps
        print(f"Epoch {epoch+1} Done. Avg Loss: {avg_loss:.4f} "
              f"(CIR: {cir_loss_avg/steps:.4f}, Cycle: {cycle_loss_avg/steps:.4f})")
        
        # ä¿å­˜æ¨¡å‹
        save_name = f"L_cycle_combiner_ep{epoch+1}.pth"
        save_path = os.path.join(save_dir, save_name)
        torch.save(model.combiner.state_dict(), save_path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {save_path}")

if __name__ == '__main__':
    train()